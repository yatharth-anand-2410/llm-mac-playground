{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üî¨ Quantized Weight Sensitivity Analysis\n",
                "\n",
                "This notebook systematically tests how much we can perturb the quantized `lm_head` weights of a 4-bit Llama 3 8B model before its output collapses.\n",
                "\n",
                "### Key Concepts\n",
                "- The `lm_head` is the final output layer that converts internal representations into word probabilities\n",
                "- In a 4-bit quantized model, weights are packed as `uint32` integers (8 x 4-bit values per uint32)\n",
                "- The real weight value is computed as: `real_weight = (packed_uint32 * scale) + bias`\n",
                "- We subtract increasing values from the raw `uint32` weights to find the breaking point"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup: Load the model and store original weights\n",
                "import mlx.core as mx\n",
                "import mlx.utils as mux\n",
                "from mlx_lm import load, generate\n",
                "\n",
                "print(\"Loading Llama 3 8B (4-bit quantized)...\")\n",
                "model_id = \"mlx-community/Meta-Llama-3-8B-Instruct-4bit\"\n",
                "model, tokenizer = load(model_id)\n",
                "\n",
                "# Store originals for restoring between tests\n",
                "original_weight = model.lm_head.weight\n",
                "original_scales = model.lm_head.scales\n",
                "original_biases = model.lm_head.biases\n",
                "\n",
                "print(f\"lm_head.weight: shape={original_weight.shape}, dtype={original_weight.dtype}\")\n",
                "print(f\"lm_head.scales: shape={original_scales.shape}, dtype={original_scales.dtype}\")\n",
                "print(f\"lm_head.biases: shape={original_biases.shape}, dtype={original_biases.dtype}\")\n",
                "print(f\"\\nFirst 10 original weight values: {original_weight.reshape(-1)[:10].tolist()}\")\n",
                "print(\"\\n‚úÖ Model loaded. Ready for experiments.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Helper function: Perturb weights and test\n",
                "def sensitivity_test(shift_amount):\n",
                "    \"\"\"Apply a shift to lm_head weights, generate a response, then restore originals.\"\"\"\n",
                "    # Reset to originals\n",
                "    model.lm_head.weight = original_weight\n",
                "    model.lm_head.scales = original_scales\n",
                "    model.lm_head.biases = original_biases\n",
                "    \n",
                "    # Apply shift (cast to int64 to avoid uint32 underflow)\n",
                "    model.lm_head.weight = (original_weight.astype(mx.int64) - shift_amount).astype(mx.uint32)\n",
                "    \n",
                "    # Generate\n",
                "    prompt = tokenizer.apply_chat_template(\n",
                "        [{\"role\": \"user\", \"content\": \"What is 2+2?\"}],\n",
                "        tokenize=False, add_generation_prompt=True\n",
                "    )\n",
                "    response = generate(model, tokenizer, prompt=prompt, verbose=False, max_tokens=10)\n",
                "    \n",
                "    # Print first 5 modified weight values for comparison\n",
                "    modified_first_5 = model.lm_head.weight.reshape(-1)[:5].tolist()\n",
                "    \n",
                "    return response, modified_first_5\n",
                "\n",
                "print(\"Helper function ready. Running experiments below...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Experiment 1: Baseline (No Shift)\n",
                "The unmodified model should respond correctly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "response, vals = sensitivity_test(0)\n",
                "print(f\"Shift: 0\")\n",
                "print(f\"Weights: {vals}\")\n",
                "print(f\"Response: '{response}'\")\n",
                "print(\"Status: HEALTHY ‚úÖ\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Experiment 2: Shift = 1 (Minimal Perturbation)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "response, vals = sensitivity_test(1)\n",
                "print(f\"Shift: 1\")\n",
                "print(f\"Weights: {vals}\")\n",
                "print(f\"Response: '{response}'\")\n",
                "print(\"Status: HEALTHY ‚úÖ ‚Äî Model is robust to single-digit shifts\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Experiment 3: Shift = 1,000,000 (Last Stable Point)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "response, vals = sensitivity_test(1_000_000)\n",
                "print(f\"Shift: 1,000,000\")\n",
                "print(f\"Weights: {vals}\")\n",
                "print(f\"Response: '{response}'\")\n",
                "print(\"Status: HEALTHY ‚úÖ ‚Äî Still coherent at 1M shift\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Experiment 4: Shift = 1,000,001 (First Signs of Degradation)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "response, vals = sensitivity_test(1_000_001)\n",
                "print(f\"Shift: 1,000,001\")\n",
                "print(f\"Weights: {vals}\")\n",
                "print(f\"Response: '{response}'\")\n",
                "print(\"Status: WOBBLING ‚ö†Ô∏è ‚Äî Response is slightly different but still coherent\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Experiment 5: Shift = 1,000,003 (Dying Mid-Sentence)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "response, vals = sensitivity_test(1_000_003)\n",
                "print(f\"Shift: 1,000,003\")\n",
                "print(f\"Weights: {vals}\")\n",
                "print(f\"Response: '{response}'\")\n",
                "print(\"Status: DYING üü† ‚Äî Correct start, then collapses into repeated tokens\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Experiment 6: Shift = 1,000,004 (Collapse After First Words)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "response, vals = sensitivity_test(1_000_004)\n",
                "print(f\"Shift: 1,000,004\")\n",
                "print(f\"Weights: {vals}\")\n",
                "print(f\"Response: '{response}'\")\n",
                "print(\"Status: COLLAPSING üî¥ ‚Äî Only first words survive, then symbol soup\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Experiment 7: Shift = 1,000,005 (Almost Fully Dead)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "response, vals = sensitivity_test(1_000_005)\n",
                "print(f\"Shift: 1,000,005\")\n",
                "print(f\"Weights: {vals}\")\n",
                "print(f\"Response: '{response}'\")\n",
                "print(\"Status: DEAD üíÄ ‚Äî Collapses after 2 words\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Experiment 8: Shift = 1,000,010 (Instant Gibberish)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "response, vals = sensitivity_test(1_000_010)\n",
                "print(f\"Shift: 1,000,010\")\n",
                "print(f\"Weights: {vals}\")\n",
                "print(f\"Response: '{response}'\")\n",
                "print(\"Status: GONE ‚ò†Ô∏è ‚Äî No coherent output from the start\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Experiment 9: Shift = 10,000,000 (Multilingual Chaos)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "response, vals = sensitivity_test(10_000_000)\n",
                "print(f\"Shift: 10,000,000\")\n",
                "print(f\"Weights: {vals}\")\n",
                "print(f\"Response: '{response}'\")\n",
                "print(\"Status: GONE ‚ò†Ô∏è ‚Äî Outputs random Chinese, code tokens, multilingual gibberish\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Experiment 10: Shift = 100,000,000 (Stuck in a Loop)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "response, vals = sensitivity_test(100_000_000)\n",
                "print(f\"Shift: 100,000,000\")\n",
                "print(f\"Weights: {vals}\")\n",
                "print(f\"Response: '{response}'\")\n",
                "print(\"Status: GONE ‚ò†Ô∏è ‚Äî So broken it gets stuck repeating one broken token\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Cleanup: Restore the Original Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Restore original weights\n",
                "model.lm_head.weight = original_weight\n",
                "model.lm_head.scales = original_scales\n",
                "model.lm_head.biases = original_biases\n",
                "\n",
                "# Verify restoration\n",
                "prompt = tokenizer.apply_chat_template(\n",
                "    [{\"role\": \"user\", \"content\": \"What is 2+2?\"}],\n",
                "    tokenize=False, add_generation_prompt=True\n",
                ")\n",
                "response = generate(model, tokenizer, prompt=prompt, verbose=False, max_tokens=10)\n",
                "print(f\"Restored model response: '{response}'\")\n",
                "print(\"\\n‚úÖ Original weights restored. Model is healthy again!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}